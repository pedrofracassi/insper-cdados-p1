{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pedro Fracasi\n",
    "- Camila Bernardi\n",
    "- Victor Assis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Contextualização\n",
    "\n",
    "League of Legends (LoL) é o maior jogo multiplayer da atualidade. Com mais de [115 milhões](https://leaguefeed.net/did-you-know-total-league-of-legends-player-count-updated/#:~:text=While%20Dota%202%20has%20around,has%201%20million%20daily%20players.) de jogadores ativos mensalmente, a comunidade está constantemente falando e opinando sobre o jogo no Twitter.\n",
    "Assim, é de interesse corporativo o conhecimento em relação a porcentagem de engajamento relacionado a tag \"lol\" na plataforma Twitter que se refere ao jogo, tâo quanto as críticas geradas ao redor do jogo e de sua comunidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Primeiro, instalamos algumas bibliotecas auxiliares pra limpeza dos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (3.6.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.9/site-packages (from nltk) (2021.9.24)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.0.1)\n",
      "/opt/conda/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package floresta to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package floresta is already up-to-date!\n",
      "/opt/conda/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/opt/conda/lib/python3.9/runpy.py:127: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package rslp to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.9/site-packages (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Instalação do nltk e pacotes adicionais, usados pra stemming, lemmetization e stopwords.\n",
    "!pip install nltk\n",
    "!python -m nltk.downloader floresta\n",
    "!python -m nltk.downloader stopwords\n",
    "!python -m nltk.downloader rslp\n",
    "\n",
    "# Instalação de algumas outras libs\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Então importamos tudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import emoji\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "/home/jovyan\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'lol.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pq eu estou caindo com gente nivel 843 no lol</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meu deus a boneca nova do lol fala \"padrãozinh...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@pauloabf26 league of legends? smp fico perdid...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muito divertido joga lol, matei a saudade daqu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pensando na vez q fiquei 14 horas em chamada c...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento Classificação\n",
       "0      pq eu estou caindo com gente nivel 843 no lol           3.0\n",
       "1  meu deus a boneca nova do lol fala \"padrãozinh...           3.0\n",
       "2  @pauloabf26 league of legends? smp fico perdid...           2.0\n",
       "3  muito divertido joga lol, matei a saudade daqu...           1.0\n",
       "4  pensando na vez q fiquei 14 horas em chamada c...           2.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bruto = pd.read_excel(filename)\n",
    "train_bruto.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meu erro foi jogar lol</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@cacpiao @louiswilliard ben feito kk lol</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fazendo voz de loli hj pra ajudar o amiguinho ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@cornetadaloud @fiaviohs ele falou que vsi ter...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>----fim da busca por webnamoro no lol----</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classificação\n",
       "0                             meu erro foi jogar lol            3.0\n",
       "1           @cacpiao @louiswilliard ben feito kk lol            0.0\n",
       "2  fazendo voz de loli hj pra ajudar o amiguinho ...            3.0\n",
       "3  @cornetadaloud @fiaviohs ele falou que vsi ter...            2.0\n",
       "4          ----fim da busca por webnamoro no lol----            2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bruto = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test_bruto.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando os tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Para a limpeza dos tweets implementou-se técnicas de retirada de pontuações, separação de espaços, separação de emojis, menções a nomes de usuários e stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pq eu est caind com gent nivel 843 no lol</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meu deu a bonec nov do lol fal padrã to vend m...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leag of legend smp fic perd de que lol voc fal</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muit divert jog lol mat a saudad daqu 3 seman ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pens na vez q fiq 14 hor em cham com um jog do...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mostr a bund pra um jog de lol</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tav jog minh vid for (jog lol) e já são 3h fod</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>só quer o emot da dian e leon no lol apen iss</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>am a gent qu vc começ a jog lol 😖  ❤ ️</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>qu tem mais títul qu tem mais torc qual tim te...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento Classificação\n",
       "0          pq eu est caind com gent nivel 843 no lol           3.0\n",
       "1  meu deu a bonec nov do lol fal padrã to vend m...           3.0\n",
       "2     leag of legend smp fic perd de que lol voc fal           2.0\n",
       "3  muit divert jog lol mat a saudad daqu 3 seman ...           1.0\n",
       "4  pens na vez q fiq 14 hor em cham com um jog do...           2.0\n",
       "5                     mostr a bund pra um jog de lol           2.0\n",
       "6     tav jog minh vid for (jog lol) e já são 3h fod           3.0\n",
       "7      só quer o emot da dian e leon no lol apen iss           2.0\n",
       "8             am a gent qu vc começ a jog lol 😖  ❤ ️           1.0\n",
       "9  qu tem mais títul qu tem mais torc qual tim te...           2.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "def limpeza (text):\n",
    "    # Remover marcações de usuários e alguns sinais de pontuação\n",
    "    pattern = re.compile('(?:\\@\\w{1,15})|[”@\\-/!.:?;,''\"]')\n",
    "    text = re.sub(pattern, '', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Stemming\n",
    "    frase = []\n",
    "    for palavra in text.split():\n",
    "        frase.append(stemmer.stem(palavra))\n",
    "    text = ' '.join(frase)\n",
    "    \n",
    "    # Separação dos emojis\n",
    "    text = ' '.join(emoji.get_emoji_regexp().split(text))\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Criando cópias dos dataframes pra poder modificar e testar\n",
    "# a limpeza sem afetar o que foi lido dos arquivos nas células acima\n",
    "train = train_bruto.copy()\n",
    "test = test_bruto.copy()\n",
    "\n",
    "train['Treinamento'] = train['Treinamento'].apply(limpeza)\n",
    "test['Teste'] = test['Teste'].apply(limpeza)\n",
    "\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nossas classificações, utilizamos os números de 0 a 3 para classificar a relevância dos tweets.\n",
    "\n",
    "|Número|Classificação|\n",
    "|-|-|\n",
    "|0|Não falou sobre LoL|\n",
    "|1|Credibiliza a marca do produto (+)|\n",
    "|2|Neutro|\n",
    "|3|Difama a marca do produto (-)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      400\n",
       "1.0      219\n",
       "3.0      212\n",
       "2.0      166\n",
       "#REF!      3\n",
       "Name: Classificação, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separação da quantia de dados referentes a cada classificação\n",
    "dados_rel = train[\"Classificação\"].value_counts()\n",
    "dados_rel_p0 = dados_rel[0]\n",
    "dados_rel_p1 = dados_rel[1]\n",
    "dados_rel_p2 = dados_rel[2]\n",
    "dados_rel_p3 = dados_rel[3]\n",
    "dados_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando Dataframes diferentes baseados nas classificações 0,1,2,3\n",
    "data_0 = train.loc[train[\"Classificação\"] == 0,:]\n",
    "data_1 = train.loc[train[\"Classificação\"] == 1,:]\n",
    "data_2 = train.loc[train[\"Classificação\"] == 2,:]\n",
    "data_3 = train.loc[train[\"Classificação\"] == 3,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação de um banco de palavras (o qual, não possui repetições)\n",
    "\n",
    "banco_de_palavras = []\n",
    "i=0\n",
    "while i<len(train[\"Treinamento\"]):\n",
    "    for palavra in train[\"Treinamento\"][i].split():\n",
    "        if palavra not in banco_de_palavras:\n",
    "            banco_de_palavras.append(palavra)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que calcula a probabilidade da frase estar naquele Dataframe\n",
    "def probabilidades(texto, banco_analisado, n):\n",
    "    \n",
    "    #P(A|B) = P(B|A) * P(A) / P(B)\n",
    "    #P.S: No caso comparativo entre a probabilidade da frase aparecer em um banco X, não há necessidade do calculo de  probabilidade de P(B), o qual seria cortado durante o cálculo\n",
    "    #P(banco_analisado|frase)\n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------------------\n",
    "    P = 1\n",
    "    #soma_palavras_no_banco = quantidade de palavras no banco de palavras que está sendo analisado\n",
    "    soma_palavras_no_banco = sum(banco_analisado[0])\n",
    "    #soma_palavras_semrep = quantidade de palavras existentes no banco de palavras total (sem repetição)\n",
    "    soma_palavras_semrep = len(banco_de_palavras)\n",
    "    #-------------------------------------------------------------------------\n",
    "    \n",
    "    #Lista auxiliar que determina o tamanho do banco que está sendo analisado \n",
    "    dados = [\n",
    "        dados_rel_p0,\n",
    "        dados_rel_p1,\n",
    "        dados_rel_p2,\n",
    "        dados_rel_p3\n",
    "    ]\n",
    "    #total = tamanho relativo do banco analisado (pesquisado na lista criada através do índice n(recebido como argumento na função))\n",
    "    #total = P\n",
    "    total = dados[n]\n",
    "    \n",
    "    #-------------------------------------------------------------------------\n",
    "    \n",
    "    #inverte as colunas com as linhas\n",
    "    banco_analisado = banco_analisado.T\n",
    "\n",
    "    #CÁLCULO DE P(B|A) \n",
    "    for palavra in texto.split(' '):\n",
    "        #Verifica se cada palavra do texto recebido está no banco de dados analisado\n",
    "        if palavra in banco_analisado.columns:\n",
    "            #Calcula a prbabilidade utilizando o suavizador de LaPlace (adiciona 1 ao numerador)\n",
    "            quantidade_dessa_palavra_banco = banco_analisado[palavra][0]\n",
    "            P*=(quantidade_dessa_palavra_banco+1)/(soma_palavras_no_banco+soma_palavras_semrep)\n",
    "        else:\n",
    "            P*=1 / (soma_palavras_no_banco + soma_palavras_semrep)\n",
    "    #-------------------------------------------------------------------------\n",
    "   \n",
    "    #CÁLCULO DE P(A|B)/P(B)\n",
    "    \n",
    "    P_banco_dado_frase = P * total\n",
    "    \n",
    "    return P_banco_dado_frase\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma série do pandas com frases em série do pandas com palavras\n",
    "\n",
    "p = pd.Series(train['Treinamento'].str.cat(sep=' ').split(' ')).value_counts().to_frame()\n",
    "pal_0 = pd.Series(data_0['Treinamento'].str.cat(sep=' ').split(' ')).value_counts().to_frame()\n",
    "pal_1 = pd.Series(data_1['Treinamento'].str.cat(sep=' ').split(' ')).value_counts().to_frame()\n",
    "pal_2 = pd.Series(data_2['Treinamento'].str.cat(sep=' ').split(' ')).value_counts().to_frame()\n",
    "pal_3 = pd.Series(data_3['Treinamento'].str.cat(sep=' ').split(' ')).value_counts().to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FUNÇÃO CRIADA PARA DETERMINAR EM QUAL BANCO UMA FRASE \"X\" É MAIS PROVÁVEL DE SER ENCONTRADA\n",
    "def comparador (texto):\n",
    "    p0 = probabilidades(texto,pal_0,0) \n",
    "    p1 = probabilidades(texto,pal_1,1) \n",
    "    p2 = probabilidades(texto,pal_2,2) \n",
    "    p3 = probabilidades(texto,pal_3,3) \n",
    "    if p0>p1 and p0>p2 and p0>p3:\n",
    "        return 0\n",
    "    elif p1>p0 and p1>p2 and p1>p3:\n",
    "        return 1\n",
    "    elif p2>p0 and p2>p1 and p2>p3:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "comparador(limpeza(\"não odeio lol\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Resultado do Modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meu err foi jog lol</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ben feit kk lol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faz voz de lol hj pra ajud o amig a consegu sk...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ele fal que vsi ter nov play no ff ou no lol</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fim da busc por webnamor no lol</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Classificação  \\\n",
       "0                                meu err foi jog lol            3.0   \n",
       "1                                    ben feit kk lol            0.0   \n",
       "2  faz voz de lol hj pra ajud o amig a consegu sk...            3.0   \n",
       "3       ele fal que vsi ter nov play no ff ou no lol            2.0   \n",
       "4                    fim da busc por webnamor no lol            2.0   \n",
       "\n",
       "   Resultado do Modelo  \n",
       "0                    1  \n",
       "1                    2  \n",
       "2                    1  \n",
       "3                    2  \n",
       "4                    2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Resultado do Modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meu err foi jog lol</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ben feit kk lol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faz voz de lol hj pra ajud o amig a consegu sk...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ele fal que vsi ter nov play no ff ou no lol</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fim da busc por webnamor no lol</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ess também é suspeitolol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>mand tud na dm 😌  😌  😌</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>md eu jog lol pq eu gost  😭  😭  😭</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>nenhum vei quer q ele jog lol cmg mas ele tá s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>as vez eu não ent qual meu problem tip sou gat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  Classificação  \\\n",
       "0                                 meu err foi jog lol            3.0   \n",
       "1                                     ben feit kk lol            0.0   \n",
       "2   faz voz de lol hj pra ajud o amig a consegu sk...            3.0   \n",
       "3        ele fal que vsi ter nov play no ff ou no lol            2.0   \n",
       "4                     fim da busc por webnamor no lol            2.0   \n",
       "..                                                ...            ...   \n",
       "95                           ess também é suspeitolol            0.0   \n",
       "96                            mand tud na dm 😌  😌  😌             0.0   \n",
       "97                 md eu jog lol pq eu gost  😭  😭  😭             1.0   \n",
       "98  nenhum vei quer q ele jog lol cmg mas ele tá s...            1.0   \n",
       "99  as vez eu não ent qual meu problem tip sou gat...            1.0   \n",
       "\n",
       "    Resultado do Modelo  \n",
       "0                     1  \n",
       "1                     2  \n",
       "2                     1  \n",
       "3                     2  \n",
       "4                     2  \n",
       "..                  ...  \n",
       "95                    0  \n",
       "96                    0  \n",
       "97                    3  \n",
       "98                    1  \n",
       "99                    0  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verificador = test\n",
    "i = 0\n",
    "verificador[\"Resultado do Modelo\"] = 0\n",
    "for frase in verificador.Teste:\n",
    "    #Cada frase do dataframe test passará pelo comparador que irá gerar o banco em que tal é mais provavel de ser encontrada\n",
    "    verificador.loc[i,\"Resultado do Modelo\"] = comparador(verificador[\"Teste\"][i])\n",
    "    i+=1\n",
    "\n",
    "verificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Resultado do Modelo</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificação</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Resultado do Modelo     0     1     2     3\n",
       "Classificação                              \n",
       "0.0                  0.32  0.06  0.06  0.04\n",
       "1.0                  0.01  0.10  0.03  0.03\n",
       "2.0                  0.02  0.05  0.06  0.05\n",
       "3.0                  0.04  0.03  0.01  0.09"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_performances = pd.crosstab(test[\"Classificação\"], test[\"Resultado do Modelo\"], normalize=True)\n",
    "tabela_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdadeiros 0: 82.05%\n",
      "Falsos 0: 17.95%\n",
      "\n",
      "Verdadeiros 1: 41.67%\n",
      "Falsos 1: 58.33%\n",
      "\n",
      "Verdadeiros 2: 37.5%\n",
      "Falsos 2: 62.5%\n",
      "\n",
      "Verdadeiros 3: 42.86%\n",
      "Falsos 3: 57.14%\n",
      "\n",
      "--------------------\n",
      "Acurácia: 57.0%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_classificador0 = tabela_performances.loc[0,0]/sum(tabela_performances.loc[:,0])\n",
    "falso_classificador0 = 1 - verdadeiros_classificador0\n",
    "\n",
    "verdadeiros_classificador1 = tabela_performances.loc[1,1]/sum(tabela_performances.loc[:,1])\n",
    "falso_classificador1 = 1 - verdadeiros_classificador1\n",
    "\n",
    "verdadeiros_classificador2 = tabela_performances.loc[2,2]/sum(tabela_performances.loc[:,2])\n",
    "falso_classificador2 = 1 - verdadeiros_classificador2\n",
    "\n",
    "verdadeiros_classificador3 = tabela_performances.loc[3,3]/sum(tabela_performances.loc[:,3])\n",
    "falso_classificador3 = 1 - verdadeiros_classificador3\n",
    "\n",
    "categorias = [verdadeiros_classificador0, verdadeiros_classificador1, verdadeiros_classificador2, verdadeiros_classificador3]\n",
    "categorias_falso = [falso_classificador0, falso_classificador1, falso_classificador2, falso_classificador3]\n",
    "\n",
    "acuracia =  tabela_performances.loc[0,0] +tabela_performances.loc[1,1] + tabela_performances.loc[2,2] + tabela_performances.loc[3,3]\n",
    "\n",
    "for i, cat in enumerate(categorias):\n",
    "    print(f'Verdadeiros {i}: {round(cat*100, 2)}%')\n",
    "    print(f'Falsos {i}: {round(categorias_falso[i]*100, 2)}%')\n",
    "    print('')\n",
    "    \n",
    "print('--------------------')\n",
    "print(f'Acurácia: {round(acuracia*100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos acima, para um modelo com 4 categorias de classificação, a performance foi bem razoável, com 60% de acertos na média. Um dos fatores que possibilitou uma média tão alta é a capacidade do modelo identificar quando o tweet usava 'lol' sem fazer referência ao jogo League of Legends, evidenciado nos 81.39% de tweets classificados como 0 corretamente.\n",
    "\n",
    "Essa alta performance na classificação 0 se deve ao fato de 'lol' também ser uma sigla inglês que significa 'Laughing Out Loud', frequentemente usada na internet por falantes da língua portuguesa, principalmente nativos de Portugal. Como tanto o jogo League of Legends quanto os portugueses tem gírias e expressões muito particulares, e o nosso classificador se baseia exclusivamente nas palavras e emojis usados na frase sem considerar qualquer aspecto linguístico, a diferenciação entre 'lol' risada e 'lol' jogo é facilitada.\n",
    "\n",
    "Esse efeito, apesar de parecer positivo, gera um viés muito grande para analisar a qualidade do modelo caso apenas a acurácia final seja considerada. Como o objetivo da empresa é saber tanto seu engajamento na tag \"lol\" como o que está sendo falado de negativo sobre ela nas redes, a apuração torna-se relevante.Entretanto, caso o cliente focaliza-se apenas nas críticas(positivas e negativas) o correto seria simplesmente descartar tweets classificados como 0, pois a investigação pressupõe que a base contém apenas conteúdo relacionada à empresa. Caso isso fosse feito, teríamos uma acurácia de, aproximadamente, 44.84%, valor substancialmente inferior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sarcasmo e Dupla negação\n",
    "O classificador Naive-Bayes considera que não há qualquer dependência entre as palavras, como se fosse uma lista de palavras aleatórias. Consequentemente, o modelo apresenta falhas por não ser capaz de perceber ironias, sarcarmos, duplas negações, figuras de linguagem ou outras frequentes ferramentas linguísticas que são constuídas com relações de dependência entre palavras. Por exemplo, um \"amo\" pode significar odeio em uma frase sarcástica, porém, como em outras frases \"amo\" estava em um contexto positivo o modelo não será capaz de diferenciar, classificando o \"amo\" sarcástico como positivo erroneamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo de frase sarcástica que seria mal-classificada pela base de dados:\n",
    "\n",
    "\"lol é tão legal, quanto ir para escola no domingo\" #Mensagem ilustrativa e *não retirada de nossa base de treinamento/teste\n",
    "\n",
    "Tal frase seria classificada como \"1\", ou seja, positivo. Entretando a classificação correta corresponderia a \"3\" (comentário negativo), tal erro ocorre em detrimento da falta de interpretação sarcástica do classificador, assim o classificador se guia naturalmente pela alta probabilidade de palavras como \"legal' estarem na classificação 1.\n",
    "\n",
    "Exemplo de frase de dupla negação que seria mal interpretada:\n",
    "\n",
    "\"não odeio lol\"\n",
    "\n",
    "A frase acima é classificada como um 3 (negativo), porém não é um comentário que deveria ser classificado como tal. Isso se dá pois o modelo, novamente, é *ingênuo*, e se baseia puramente na matemática pra classificação, sem interpretar o texto. A presença da palavra \"odeio\" na frase provavelmente é o bastante para \"puxar\" a classificação pro 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expansão\n",
    "    \n",
    "Não é possível alimentar a base de treinamento automaticamente a partir dos resultados do próprio classificador, uma vez que erros de classificação seriam multiplicados exponencialmente, gerando uma inacurácia cada vez maior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sugestões de Melhorias para o classificador\n",
    "\n",
    "Algumas melhorias que poderiam ser implementadas incluem:\n",
    "\n",
    "- O agrupamento de palavras próximas, como o \"não odeio\" do último exemplo. Isso deixaria o classificador um pouco menos ingênuo, pois o sentido de pedaços da frase começaria a ser levado em conta, embora que ainda de forma bem ingênua.\n",
    "\n",
    "- Substituição de emojis pelos seus significados em português (através da lib emoji). Embora emojis muitas vezes sejam usados com significados completamente diferentes dos nominais, o uso de palavras em português no lugar deles permitiria o stemming.\n",
    "\n",
    "- Treinamento com um maior número de Tweets, talvez com um sistema onde o próprio classificador classifica e o usuário indica se a classificação foi certa ou errada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferentes cenários de aplicação do classificador Naive Bayes\n",
    "\n",
    "Classificadores Naive Bayes são muito úteis para o processamento e classificação de texto em diversas aplicações, como:\n",
    "\n",
    "- Filtro de spam de emails (com base nas marcações prévias de spam dos usuários)\n",
    "- Identificação de fraudes baseada no histórico de uso de um usuário \n",
    "- Recomendações de conteúdo com base no feedback do usuário (like/dislike)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frases</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pq eu est caind com gent nivel 843 no lol</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meu deu a bonec nov do lol fal padrã to vend m...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leag of legend smp fic perd de que lol voc fal</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>muit divert jog lol mat a saudad daqu 3 seman ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pens na vez q fiq 14 hor em cham com um jog do...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>ess também é suspeitolol</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>mand tud na dm 😌  😌  😌</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>md eu jog lol pq eu gost  😭  😭  😭</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>nenhum vei quer q ele jog lol cmg mas ele tá s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>as vez eu não ent qual meu problem tip sou gat...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Frases Classificação\n",
       "0             pq eu est caind com gent nivel 843 no lol           3.0\n",
       "1     meu deu a bonec nov do lol fal padrã to vend m...           3.0\n",
       "2        leag of legend smp fic perd de que lol voc fal           2.0\n",
       "3     muit divert jog lol mat a saudad daqu 3 seman ...           1.0\n",
       "4     pens na vez q fiq 14 hor em cham com um jog do...           2.0\n",
       "...                                                 ...           ...\n",
       "1095                           ess também é suspeitolol           0.0\n",
       "1096                            mand tud na dm 😌  😌  😌            0.0\n",
       "1097                 md eu jog lol pq eu gost  😭  😭  😭            1.0\n",
       "1098  nenhum vei quer q ele jog lol cmg mas ele tá s...           1.0\n",
       "1099  as vez eu não ent qual meu problem tip sou gat...           1.0\n",
       "\n",
       "[1100 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coluna = range(0,1100)\n",
    "\n",
    "train_cp = train.copy().rename(columns={'Treinamento': 'Frases'})\n",
    "test_cp = test.copy().rename(columns={'Teste': 'Frases'})\n",
    "\n",
    "tt = pd.concat([train_cp, test_cp])\n",
    "tt = tt.drop('Resultado do Modelo', axis=1)\n",
    "tt = tt.reset_index()\n",
    "tt = tt.drop(labels='index', axis=1)\n",
    "\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Resultado do Modelo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meu err foi jog lol</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ben feit kk lol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>faz voz de lol hj pra ajud o amig a consegu sk...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ele fal que vsi ter nov play no ff ou no lol</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fim da busc por webnamor no lol</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ess também é suspeitolol</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>mand tud na dm 😌  😌  😌</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>md eu jog lol pq eu gost  😭  😭  😭</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>nenhum vei quer q ele jog lol cmg mas ele tá s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>as vez eu não ent qual meu problem tip sou gat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste  Classificação  \\\n",
       "0                                 meu err foi jog lol            3.0   \n",
       "1                                     ben feit kk lol            0.0   \n",
       "2   faz voz de lol hj pra ajud o amig a consegu sk...            3.0   \n",
       "3        ele fal que vsi ter nov play no ff ou no lol            2.0   \n",
       "4                     fim da busc por webnamor no lol            2.0   \n",
       "..                                                ...            ...   \n",
       "95                           ess também é suspeitolol            0.0   \n",
       "96                            mand tud na dm 😌  😌  😌             0.0   \n",
       "97                 md eu jog lol pq eu gost  😭  😭  😭             1.0   \n",
       "98  nenhum vei quer q ele jog lol cmg mas ele tá s...            1.0   \n",
       "99  as vez eu não ent qual meu problem tip sou gat...            1.0   \n",
       "\n",
       "    Resultado do Modelo  \n",
       "0                     1  \n",
       "1                     2  \n",
       "2                     1  \n",
       "3                     2  \n",
       "4                     2  \n",
       "..                  ...  \n",
       "95                    0  \n",
       "96                    0  \n",
       "97                    3  \n",
       "98                    1  \n",
       "99                    0  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(texto,banco_analisado,dados,n):\n",
    "    P = 1\n",
    "    #P(A|B) = P(B|A) * P(A) / P(B)\n",
    "    #P(banco_analisado|frase)\n",
    "    \n",
    "    soma_palavras_no_banco = sum(banco_analisado[0])\n",
    "    #soma_palavras_total = sum(p[0])\n",
    "    soma_palavras_semrep = len(banco_de_palavras)\n",
    "    \n",
    "    total = dados[n]\n",
    "    \n",
    "    #inverte as colunas com as linhas\n",
    "    banco_analisado = banco_analisado.T\n",
    "\n",
    "    for palavra in texto.split(' '):\n",
    "        #Verifica se cada palavra do texto recebido está no banco de dados analisado\n",
    "        if palavra in banco_analisado.columns:\n",
    "            #Calcula a prbabilidade utilizando o suavizador de LaPlace (adiciona 1 ao numerador)\n",
    "            quantidade_dessa_palavra_banco = banco_analisado[palavra][0]\n",
    "            P*=(quantidade_dessa_palavra_banco+1)/(soma_palavras_no_banco+soma_palavras_semrep)\n",
    "        else:\n",
    "            P*=1 / (soma_palavras_no_banco + soma_palavras_semrep)\n",
    "    #P = P(B|A)\n",
    "    \n",
    "    P_banco_dado_frase = P * total\n",
    "    \n",
    "    return P_banco_dado_frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4034545454545455"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def verifica_performance_simples(df):\n",
    "    p=0\n",
    "    for i in range(len(df)):\n",
    "        if df.loc[i,\"Resultado do Modelo\"] == df.loc[i,\"Classificação\"]:\n",
    "            p +=1   \n",
    "    acuracia = p/len(df)    \n",
    "    return acuracia\n",
    "\n",
    "# Porcentagem de tweets que serão usados pro teste\n",
    "tamanho_teste = 0.1\n",
    "\n",
    "# Quantidade de vezes que o teste será executado\n",
    "loops_teste = 100\n",
    "\n",
    "tamanho_df = tt.shape[0]\n",
    "performances = []\n",
    "\n",
    "for i in range(loops_teste):\n",
    "    #Randomiza os tweets e emite um novo df de teste(novo_teste) com 10% dos tt's e treinamento\n",
    "    novo_treinamento, novo_teste = train_test_split(tt, test_size=tamanho_teste)\n",
    "    novo_teste = novo_teste.copy()\n",
    "    novo_treinamento = novo_treinamento.copy()\n",
    "    \n",
    "    #Cria os novos dataframes a serem utilizados\n",
    "    data_0 = novo_treinamento.loc[novo_treinamento[\"Classificação\"] == 0,:]\n",
    "    data_1 = novo_treinamento.loc[novo_treinamento[\"Classificação\"] == 1,:]\n",
    "    data_2 = novo_treinamento.loc[novo_treinamento[\"Classificação\"] == 2,:]\n",
    "    data_3 = novo_treinamento.loc[novo_treinamento[\"Classificação\"] == 3,:]\n",
    "\n",
    "    #separa pelas frases\n",
    "    pal_0 = pd.Series(data_0['Frases'].str.cat(sep=' ').split(' ')).value_counts().to_frame()\n",
    "    pal_1 = pd.Series(data_1['Frases'].str.cat(sep=' ').split(' ')).value_counts().to_frame()\n",
    "    pal_2 = pd.Series(data_2['Frases'].str.cat(sep=' ').split(' ')).value_counts().to_frame()\n",
    "    pal_3 = pd.Series(data_3['Frases'].str.cat(sep=' ').split(' ')).value_counts().to_frame()\n",
    "\n",
    "    #guarda os dados relativos de cada classificação\n",
    "    dados_rel = novo_treinamento[\"Classificação\"].value_counts()\n",
    "    dados_rel_p0 = dados_rel[0]\n",
    "    dados_rel_p1 = dados_rel[1]\n",
    "    dados_rel_p2 = dados_rel[2]\n",
    "    dados_rel_p3 = dados_rel[3]\n",
    "    #lista os dados relativos\n",
    "    dados = [dados_rel_p0,dados_rel_p1,dados_rel_p2,dados_rel_p3]\n",
    "    \n",
    "    # Cria a coluna Resultado do Modelo no novo_teste\n",
    "    novo_teste[\"Resultado do Modelo\"] = 0\n",
    "    \n",
    "    #Reseta o index\n",
    "    novo_teste = novo_teste.reset_index()\n",
    "    novo_teste = novo_teste.drop(labels='index',axis=1)\n",
    "    \n",
    "    novo_treinamento = novo_treinamento.reset_index()\n",
    "    novo_treinamento = novo_treinamento.drop(labels='index',axis=1)\n",
    "    \n",
    "    #Preenche o Resultado Modelo com base no comparador\n",
    "    y = 0\n",
    "    for frases in novo_teste.Frases:\n",
    "        frase = novo_teste[\"Frases\"][y]\n",
    "        \n",
    "        #Calcula a probabilidade da frase corresponder a cada classificação\n",
    "        p0 = prob(frase,pal_0,dados,0) \n",
    "        p1 = prob(frase,pal_1,dados,1) \n",
    "        p2 = prob(frase,pal_2,dados,2) \n",
    "        p3 = prob(frase,pal_3,dados,3) \n",
    "        if p0>p1 and p0>p2 and p0>p3:\n",
    "            x =  0\n",
    "        elif p1>p0 and p1>p2 and p1>p3:\n",
    "            x = 1\n",
    "        elif p2>p0 and p2>p1 and p2>p3:\n",
    "            x =  2\n",
    "        else:\n",
    "            x =  3\n",
    "        #mostra a nova classificação\n",
    "        novo_teste.loc[x,\"Resultado do Modelo\"] = x\n",
    "        y+=1\n",
    "    #Guarda a performance\n",
    "    performances.append(verifica_performance_simples(novo_teste))\n",
    "    \n",
    "sum(performances)/len(performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Constrói histograma com os percentuais de acerto\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(performances, edgecolor = 'white')\n",
    "plt.ylabel('Quantidade de performances')\n",
    "plt.xlabel('Performance em decimal')\n",
    "plt.title('Performance a cada reorganização do DataFrame')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências bibliográficas\n",
    "\n",
    "[Examples for Portuguese Processing - nltk](http://www.nltk.org/howto/portuguese_en.html)\n",
    "\n",
    "[STOP WORDS – COMO FUNCIONAM PALAVRAS DE PARADA?](https://www.agenciamestre.com/seo/stop-words-como-funcionam-palavras-de-parada/)\n",
    "\n",
    "[APLICAÇÕES PRÁTICAS DE MINERAÇÃO DE DADOS E ALGORITMO DE NAIVE BAYES](https://www.webartigos.com/artigos/aplicacoes-praticas-de-mineracao-de-dados-e-algoritmo-de-naive-bayes/165614)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
